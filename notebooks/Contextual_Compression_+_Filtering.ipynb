{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain huggingface_hub openai chromadb tiktoken faiss-cpu\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install -U FlagEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "## Text Splitting & Docloader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "Besw1K5jqQV-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BGE Embeddings"
      ],
      "metadata": {
        "id": "378x9zFvp-Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en-v1.5\"\n",
        "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
        "\n",
        "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={'device': 'cuda'},\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "CH1VEgdfp9TF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data prep\n"
      ],
      "metadata": {
        "id": "YTDxLMs_vg8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = [\n",
        "    TextLoader('tamil.txt'),\n",
        "]\n",
        "docs = []\n",
        "for l in loaders:\n",
        "    docs.extend(l.load())"
      ],
      "metadata": {
        "id": "eAazrw6RP9Y5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "laXv7OoAo29M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "vJwE3-158Ez8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for printing docs\n",
        "\n",
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
      ],
      "metadata": {
        "id": "IfCt8bhHNu9u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = FAISS.from_documents(texts,\n",
        "                                 bge_embeddings\n",
        "                                #  OpenAIEmbeddings()\n",
        "                                 ).as_retriever()\n",
        "\n",
        "docs = retriever.get_relevant_documents(\"What is tamil?\")\n",
        "#lets look at the docs\n",
        "pretty_print_docs(docs)"
      ],
      "metadata": {
        "id": "BK4tvafU6ve3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding contextual compression with an LLMChainExtractor\n",
        "\n",
        "Now let's wrap our base retriever with a ContextualCompressionRetriever. We'll add an LLMChainExtractor, which will iterate over the initially returned documents and extract from each only the content that is relevant to the query."
      ],
      "metadata": {
        "id": "UUitgRmDqVPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "# making the compressor\n",
        "llm = OpenAI(temperature=0)\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "\n",
        "# it needs a base retriever (we're using FAISS Retriever) and a compressor (Made above)\n",
        "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor,\n",
        "                                                       base_retriever=retriever)"
      ],
      "metadata": {
        "id": "QKgOwvftqV2B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compressor prompt\n",
        "compressor.llm_chain.prompt"
      ],
      "metadata": {
        "id": "QCxODrgMStUR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs = compression_retriever.get_relevant_documents(\"What is tamil?\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "_nh7iDks9ELR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More built-in compressors: filters\n",
        "\n",
        "### LLMChainFilter\n",
        "\n",
        "Uses an LLM chain to select out the queries to show the final LLM - This could be shown to a model fine tuned to do this\n",
        "\n",
        "\"YES\" we show it or \"NO\" we don't show it"
      ],
      "metadata": {
        "id": "avCDLMDZqdPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainFilter\n",
        "\n",
        "_filter = LLMChainFilter.from_llm(llm)\n"
      ],
      "metadata": {
        "id": "6NgvgNU1q6af"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_filter.llm_chain.prompt"
      ],
      "metadata": {
        "id": "HK3maPyITgL2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_retriever = ContextualCompressionRetriever(base_compressor=_filter, base_retriever=retriever)\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\"What is tamil\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "RobKDkFSTeZ4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EmbeddingsFilter\n",
        "Use an Embedding model to filter out the results that are closest to the query"
      ],
      "metadata": {
        "id": "K9n2gShUrBf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
        "compression_retriever = ContextualCompressionRetriever(base_compressor=embeddings_filter, base_retriever=retriever)\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\"What is tamil\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "qztjRgdGrCfg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipelines\n",
        "\n",
        "\n",
        "### Stringing compressors and document transformers together\n",
        "\n",
        "DocumentCompressorPipeline allows us to string things together.\n",
        "\n",
        "BaseDocumentTransformers - can do transformations on the docs -eg. split the text and\n",
        "\n",
        "EmbeddingsRedundantFilter - filter out what is not related after a split or transformation\n",
        "\n"
      ],
      "metadata": {
        "id": "vpvfUtsIrKMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
        "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\". \")\n",
        "\n",
        "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
        "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
        "\n",
        "## making the pipeline\n",
        "pipeline_compressor = DocumentCompressorPipeline(\n",
        "    transformers=[splitter, redundant_filter, relevant_filter]\n",
        ")"
      ],
      "metadata": {
        "id": "2aNs6gz8rhZu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_retriever = ContextualCompressionRetriever(base_compressor=pipeline_compressor,\n",
        "                                                       base_retriever=retriever)\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\"What is tamil\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "dOBkTER5rknh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### different pipeline\n",
        "\n",
        "## making the pipeline\n",
        "pipeline_compressor = DocumentCompressorPipeline(\n",
        "    transformers=[splitter, compressor, redundant_filter, relevant_filter]\n",
        ")"
      ],
      "metadata": {
        "id": "Zfhxnm0zcxao"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_retriever = ContextualCompressionRetriever(base_compressor=pipeline_compressor,\n",
        "                                                       base_retriever=retriever)\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\"What is tamil\")\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "id": "XDQ2ilESdF5l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples Pipelines\n",
        "\n",
        "**Example 1** - filter, rewrite, check with embeddings\n",
        "\n",
        "**Example 2** - retrieve multiple sources [ensemble], filter, rewrite,\n",
        "\n",
        "**Example 3** - retrieve, split, check splits with embeddings, filter, rewrite,"
      ],
      "metadata": {
        "id": "jaCADJfaUFuy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Xx4Tw13VxDA"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}